{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Neuroimaging in Python\n",
    "\n",
    "If you are running this from the SciNet jupyter hub, then use the paths in the top half of the block below.\n",
    "\n",
    "If you are running this on a local laptop, edit the bottom of the first block with the paths to your desired direcoties.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are going to use a single subject from the ABIDE dataset.\n",
    "import os\n",
    "\n",
    "# # ## use these commands if you are running this on scinet\n",
    "my_home = os.environ.get('HOME')\n",
    "my_scratch = my_home.replace('/home/', '/scratch/')\n",
    "tutorial_dir = os.path.join(my_scratch, 'ss2017_mripython')\n",
    "my_nilearn_data = os.path.join(tutorial_dir, 'data','nilearn_data')\n",
    "cc200_nii = os.path.join(os.path.dirname(os.getcwd()), 'rois', 'cc200_roi_atlas.nii.gz')\n",
    "\n",
    "## if this directory doesn't exist - make it..\n",
    "rois_dir = os.path.join(tutorial_dir, 'data', 'rois')\n",
    "if not os.path.exists(rois_dir):\n",
    "    os.makedirs(rois_dir)\n",
    "\n",
    "# ## edit this section if you are running this one your own laptop\n",
    "# tutorial_dir ='/home/edickie/Documents/ss2017_16pythonmri/'  ## point this to the location where you want the data\n",
    "# my_nilearn_data = os.path.join(tutorial_dir, 'data', 'nilearn_data') \n",
    "\n",
    "# ## point this to the location of the craddock atlas you downloaded\n",
    "# cc200_nii = os.path.join(tutorial_dir, 'data', 'rois', 'cc200_roi_atlas.nii.gz') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this makes the plots show up..\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using nilearn data fetchers to grab our tutorial dataset\n",
    "\n",
    "We are grabbing data from the ABIDE dataset. A data sharing initiative with over 1000 scans. Check out the references included in the abide object for more info. \n",
    "\n",
    "Thanks to the work of the proprocessed connectome project. A lot of the data processing work has been done for us! We are going to grab the preprocessed but unfilted resting stat MR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "# We specify the site and number of subjects we want to download\n",
    "abide = datasets.fetch_abide_pcp(data_dir=my_nilearn_data,\n",
    "                                 derivatives=['func_mean', 'func_preproc', 'func_mask'],\n",
    "                                 quality_checked= True, \n",
    "                                 n_subjects = 4)\n",
    "\n",
    "print(abide.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}'.format(abide.description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abide.func_preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we will define the files we want to work with for the rest of the tutorial \n",
    "\n",
    "We need:\n",
    "    + some Regions of Interest (rois) to use as masks for our analysis\n",
    "    + a functional MR image\n",
    "    + (for plotting) The mean of our functional MR image\n",
    "    + (for masking) a mask defining the brain vs outside of head\n",
    "    + to decide which roi we will focus on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rois = cc200_nii\n",
    "func = abide.func_preproc[3]\n",
    "mask = abide.func_mask[3]\n",
    "mean_func = abide.func_mean[3]\n",
    "roi = 174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "plotting.plot_roi(cc200_nii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_roi(cc200_nii, bg_img=mean_func, alpha = 0.5, title = \"cc200 atlas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using nibabel to load nifti images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for interacting with NIFTI files\n",
    "import nibabel as nib\n",
    "\n",
    "func_nib = nib.load(func)\n",
    "print(func_nib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = func_nib.get_affine()\n",
    "affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = func_nib.affine\n",
    "affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = func_nib.get_header()\n",
    "print(header.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dimensions for the fMRI file\n",
    "dims = func_nib.shape\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get data to extract the data from it\n",
    "func_data = func_nib.get_data()\n",
    "func_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape to voxels * timepoints (4D --> 2D)\n",
    "func_data = func_data.reshape(dims[0]*dims[1]*dims[2], dims[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkling that our functional and mask files have the same dimensions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the same thing for rois\n",
    "rois_data = nib.load(cc200_nii).get_data()\n",
    "\n",
    "print(rois_data.shape)\n",
    "\n",
    "if rois_data.shape[0:2] == dims[0:2]:\n",
    "    print(\"ROIs and func file dimensions match, Hooray!!\")\n",
    "else:\n",
    "    print(\"FAIL, they do not match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nilearn to sample the rois nifti file so that they match in dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "\n",
    "\n",
    "    \n",
    "resampled_cc200 = image.resample_to_img(cc200_nii, mean_func, interpolation = 'nearest')\n",
    "\n",
    "plotting.plot_roi(resampled_cc200, mean_func)\n",
    "\n",
    "resampled_cc200.to_filename(os.path.join(rois_dir, \"resample_cc200.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the same thing for rois\n",
    "new_rois = os.path.join(tutorial_dir, 'data', 'rois', \"resample_cc200.nii.gz\")\n",
    "rois_data = nib.load(new_rois).get_data()\n",
    "\n",
    "print(rois_data.shape)\n",
    "\n",
    "if rois_data.shape[0:2] == dims[0:2]:\n",
    "    print(\"ROIs and func file dimensions match, Hooray!!\")\n",
    "else:\n",
    "    print(\"FAIL, they do not match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating our own seed correlation map using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rois_data = rois_data.reshape(dims[0]*dims[1]*dims[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating our mean timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# get the seed time series\n",
    "idx = np.where(rois_data == roi)[0]\n",
    "ts = np.mean(func_data[idx, :], axis=0)\n",
    "\n",
    "# look at the timeseries\n",
    "plt.plot(ts)\n",
    "plt.show()\n",
    "len(ts) # looks like it's the right length (i.e., our axis is correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlate the mean timeseries with the timeseries from every voxel in the func file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an output matrix\n",
    "output = np.zeros(dims[0]*dims[1]*dims[2])\n",
    "\n",
    "# correlate seed against all voxels\n",
    "for i in range(dims[0]*dims[1]*dims[2]):\n",
    "    output[i] = np.corrcoef(ts, func_data[i, :])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When will do a faster and with no \"true divide\" warning if we incorporate the brain mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add a mask to get rid of the weird bits\n",
    "mask_data = nib.load(mask).get_data()\n",
    "mask_data = mask_data.reshape(dims[0]*dims[1]*dims[2], 1)\n",
    "idx_mask = np.where(mask_data > 0)[0]\n",
    "\n",
    "## recalculate the ts taking the mask into account\n",
    "idx_masked = np.intersect1d(idx,idx_mask)\n",
    "ts = np.mean(func_data[idx_masked, :], axis=0)\n",
    "\n",
    "# make an output matrix\n",
    "output = np.zeros(dims[0]*dims[1]*dims[2])\n",
    "\n",
    "# correlate seed against all voxels\n",
    "for i in np.arange(len(idx_mask)):\n",
    "    output[idx_mask[i]] = np.corrcoef(ts, func_data[idx_mask[i], :])[0][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using nibabel to write our result out to a nifti file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(rois_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get back to 4D\n",
    "output_filename = os.path.join(tutorial_dir, 'seed_correlation.nii.gz')\n",
    "output = np.reshape(output, (dims[0], dims[1], dims[2], 1))\n",
    "\n",
    "# write the results into a NIFTI file\n",
    "output = nib.nifti1.Nifti1Image(output, affine)\n",
    "output.to_filename(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nilearn's glass brain and statmap plots help us visualize our new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_glass_brain(output_filename, threshold = 0.5, \n",
    "                          colorbar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(output_filename, threshold = 0.3, \n",
    "                          colorbar = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## instead of calculating one mean timeseries, let's do it for the whole atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output matrix\n",
    "output_ts = np.zeros((len(np.unique(rois_data))-1, dims[3]))\n",
    "\n",
    "# rois_data_masked = np.multiply(rois_data,mask_data)\n",
    "# load in all mean time series from atlas\n",
    "for i, roi in enumerate(np.unique(rois_data)):\n",
    "    if roi > 0:\n",
    "        idx = np.where(rois_data == roi)[0]\n",
    "        ts = np.mean(func_data[idx, :], axis=0)\n",
    "        output_ts[i-1, :] = ts\n",
    "\n",
    "# correlation matrix\n",
    "cc200_correl = np.corrcoef(output_ts)\n",
    "\n",
    "# view output\n",
    "plt.imshow(cc200_correl, interpolation='nearest', cmap=plt.cm.RdBu_r)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The seaborn package has some really awesome option..uncluding and easy clustered heatmap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "\n",
    "seaborn.clustermap(cc200_correl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting fancier with nilearn\n",
    "\n",
    "nilearn was built by people doing machine learning of resting state fMRI data using sci-kit learn.\n",
    "\n",
    "It has A LOT of functionallity beyond what we have time to teach here. Including:\n",
    "+ image manipulation (smoothing, resampling)\n",
    "+ algorithms (ICA and dictionary learning) for parcellating your own dataset (i.e. defining your own ROIS) \n",
    "+ timeseries extraction with many many options for filtering, detrending \n",
    "+ multiple methods for covariance esimtaiton (i.e. partial correlation, covariance, lasso..)\n",
    "+ machine learning and cross validation\n",
    "\n",
    "They also did a beautiful job of building a large set of ipython notebook tutorials to teach you about all these methods.\n",
    "\n",
    "Go to the [the nilean website](http://nilearn.github.io/index.html) for more info.\n",
    "\n",
    "Let's use another example to see some of the more complex things nilearn can do...\n",
    "\n",
    "We'll start by using the data fetcher to grab a different atlas. This one (dosenbach_2010) if a set of coordinates in the brain to sample from.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "dosenbach = datasets.fetch_coords_dosenbach_2010()\n",
    "print(dosenbach.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nilearn's sphere masker to extract the timeseries\n",
    "\n",
    "nilearn has a built in function for extracting timeseries from functional files and doing a little extra signal processing at the same time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data\n",
    "\n",
    "spheres_masker = input_data.NiftiSpheresMasker(\n",
    "    seeds=dosenbach.rois, #the seeds are the dosenbach roi atlas\n",
    "    smoothing_fwhm=4, radius=4.5, # set the radius of a sphere around the roi you want extracted\n",
    "    standardize=True, # the time-series are centered and normed (mean 0, variance 1 in the time dimension)\n",
    "    detrend=True, low_pass=0.1, high_pass=0.01, t_r=2.5) # additional signal cleaning and filtering params\n",
    "\n",
    "timeseries = spheres_masker.fit_transform(func)\n",
    "\n",
    "print(\"the shape of the timeseries is {}\".format(timeseries.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using nilearn's ConnectivityMeasure to calculate our correlation matrix\n",
    "\n",
    "Avalable options are “correlation”, “partial correlation”, “tangent”, “covariance”, “precision” or other utilites in sci-py could be plugged in ([see here for an example](http://nilearn.github.io/auto_examples/03_connectivity/plot_multi_subject_connectome.html#sphx-glr-auto-examples-03-connectivity-plot-multi-subject-connectome-py))\n",
    "\n",
    "Let's do partial correlation this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from nilearn import plotting\n",
    "\n",
    "correlation_measure = ConnectivityMeasure(kind='covariance')\n",
    "dosenbach_matrix = correlation_measure.fit_transform([timeseries])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.clustermap(dosenbach_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "coords = np.vstack((\n",
    "    dosenbach.rois['x'],\n",
    "    dosenbach.rois['y'],\n",
    "    dosenbach.rois['z'],\n",
    ")).T\n",
    "\n",
    "plotting.plot_connectome(dosenbach_matrix, node_coords = coords, edge_threshold='98%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6_nilearn_01",
   "language": "python",
   "name": "3.6_nilearn_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
